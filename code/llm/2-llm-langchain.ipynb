{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1617dfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from os.path import isfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e897dfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"YOUR API KEY GOES HERE\"\n",
    "OPENAI_API_MODEL = 'gpt-3.5-turbo-0125'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3141de60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silence setting with copy warning\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba8648f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a multilingual specialist that classifies speeches in parliament.\n",
    "\n",
    "    You will read texts that come in many different languages.\n",
    "    \n",
    "    Then you will classify it with a word or short phrase, considering topics that are\n",
    "    usually covered in the EU Parliament.\n",
    "    \n",
    "    Some example topics would be: 'parliament procedures', 'elections', 'climate', 'war',\n",
    "    'technology', 'innovation', 'finance', 'migration', 'industry', 'democracy'. This list is not\n",
    "    exhaustive.\n",
    "    \n",
    "    Notice that one speech might include more than one topic. If needed, classify it over more than\n",
    "    one tag as well.\n",
    "        \n",
    "    You will also note down in which language the source text was.\n",
    "\n",
    "    Return the output in the format specified in the Classification class provided.\n",
    "    \n",
    "    An example input would be:\n",
    "    \n",
    "    ```A União Europeia precisa de mais esforços para combater as mudanças climáticas, que\n",
    "    estão afetando todo o planeta. O clima está mudando. E a guerra na Ucrânia segue sendo um problema.\n",
    "    Precisamos parar com a guerra.```\n",
    "    \n",
    "    An the exemple output would be:\n",
    "    \n",
    "    topic: climate, war\n",
    "    language: portuguese\n",
    "\n",
    "    The text for translation is below:\n",
    "\n",
    "    ---\n",
    "    {text}.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "class Classifxqication(BaseModel):\n",
    "    topic: str = Field(description=\"The main topic of the text\")\n",
    "    language: str = Field(description=\"The language the text is written in\")\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(temperature=0.1, \n",
    "                 model=OPENAI_API_MODEL, \n",
    "                 openai_api_key=OPENAI_API_KEY).with_structured_output(\n",
    "    Classification\n",
    ")\n",
    "\n",
    "tagging_chain = tagging_prompt | llm\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddcedcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts how many tokens we will have on each row\n",
    "def count_tokens(text):\n",
    "    # Initialize the tokenizer with the model's encoding\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "    # Encode the text to get the token count\n",
    "    tokens = encoding.encode(text)\n",
    "    token_count = len(tokens)\n",
    "\n",
    "    return token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6db31654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits the given DataFrame into chunks of specified size.\n",
    "def split_dataframe(df, chunk_size=30):\n",
    "    return [df[i:i + chunk_size] for i in range(0, df.shape[0], chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb2e75d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all the chunks and concat\n",
    "df = pd.concat([pd.read_csv(f) for f in glob.glob(\"../output/lang-detected/chunks/*.csv\")])\n",
    "# Keep only the last legislature entries\n",
    "df = df[df.date >= \"2019-06-02\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28eb7ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts the tokens\n",
    "df['token_count'] = df.speech.apply(count_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8e33e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are two very long speeches, with more than 16k tokens. They would be truncated,\n",
    "# so we got rid of them as well.\n",
    "long_entries = df[df.token_count > 16000].copy()\n",
    "df = df[df.token_count <= 16000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d24680d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>speech</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker_span</th>\n",
       "      <th>fname</th>\n",
       "      <th>date</th>\n",
       "      <th>term</th>\n",
       "      <th>year</th>\n",
       "      <th>speech_length_in_characters</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104132</th>\n",
       "      <td>119658</td>\n",
       "      <td>195644</td>\n",
       "      <td>Νίκος Χριστοδουλίδης, Πρόεδρος της Κυπριακής Δ...</td>\n",
       "      <td>generic photo, parse from text</td>\n",
       "      <td>4. This is Europe - Debate with the President ...</td>\n",
       "      <td>Νίκος Χριστοδουλίδης,</td>\n",
       "      <td>../output/csvs/parsed-9-2023-06-13.csv</td>\n",
       "      <td>2023-06-13</td>\n",
       "      <td>9</td>\n",
       "      <td>2023</td>\n",
       "      <td>29933.0</td>\n",
       "      <td>18308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171302</th>\n",
       "      <td>197600</td>\n",
       "      <td>341284</td>\n",
       "      <td>Κυριάκος Μητσοτάκης, Πρωθυπουργός της Ελλάδας....</td>\n",
       "      <td>generic photo, parse from text</td>\n",
       "      <td>4. This is Europe - Debate with the Prime Mini...</td>\n",
       "      <td>Κυριάκος Μητσοτάκης,</td>\n",
       "      <td>../output/csvs/parsed-9-2022-07-05.csv</td>\n",
       "      <td>2022-07-05</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "      <td>22952.0</td>\n",
       "      <td>20313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        level_0   index                                             speech  \\\n",
       "104132   119658  195644  Νίκος Χριστοδουλίδης, Πρόεδρος της Κυπριακής Δ...   \n",
       "171302   197600  341284  Κυριάκος Μητσοτάκης, Πρωθυπουργός της Ελλάδας....   \n",
       "\n",
       "                            speaker_id  \\\n",
       "104132  generic photo, parse from text   \n",
       "171302  generic photo, parse from text   \n",
       "\n",
       "                                                  subject  \\\n",
       "104132  4. This is Europe - Debate with the President ...   \n",
       "171302  4. This is Europe - Debate with the Prime Mini...   \n",
       "\n",
       "                 speaker_span                                   fname  \\\n",
       "104132  Νίκος Χριστοδουλίδης,  ../output/csvs/parsed-9-2023-06-13.csv   \n",
       "171302   Κυριάκος Μητσοτάκης,  ../output/csvs/parsed-9-2022-07-05.csv   \n",
       "\n",
       "              date  term  year  speech_length_in_characters  token_count  \n",
       "104132  2023-06-13     9  2023                      29933.0        18308  \n",
       "171302  2022-07-05     9  2022                      22952.0        20313  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(long_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1ff61d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a75f20decc4c7e98b9d1f3580ecc71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=594.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Splits the dataframe \n",
    "chunk_size = 100\n",
    "dfs = split_dataframe(df, chunk_size=chunk_size)\n",
    "for i, subset in enumerate(tqdm(dfs)):\n",
    "                      \n",
    "    fname = f\"../output/classified-llm/{chunk_size}_{i+1}.csv\"\n",
    "    if isfile(fname):\n",
    "        continue\n",
    "    \n",
    "    # could also depend on the ammount of tokens in the dataframe.\n",
    "    results = tagging_chain.batch([{'text': text} for text in subset['speech']], \n",
    "                          config={\"max_concurrency\": 70})\n",
    "    \n",
    "    # Saves the topic and language classification back in the dataframe\n",
    "    subset['topic'] = [result.topic for result in results]\n",
    "    subset['language'] = [result.language for result in results]\n",
    "\n",
    "    # Saves it as CSV\n",
    "    subset.to_csv(fname)\n",
    "    \n",
    "    if i % 20 == 0:\n",
    "        time.sleep(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
